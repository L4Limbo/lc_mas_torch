{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import matutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vocabulary and Vectors\n"
     ]
    }
   ],
   "source": [
    "print('Loading Vocabulary and Vectors')\n",
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    'data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "vocabulary = json.load(open('data/processed_data/processed_data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([[1051,   26,  337,  110,  960,    5,  190,  708,   28,  196,  435,  296,\n",
    "          247, 6134, 3361,   99,   25,  247,  837,  721,    5, 1012,   12, 1927,\n",
    "         3721,   51,   55,   56,   57,    1,   58,    1,   59,    1,   33,   60,\n",
    "           52,  247, 1435, 6134]])\n",
    "\n",
    "generated = torch.tensor([[6135, 4049,  326, 5387, 4024, 5655, 2617, 2519, 3334, 2143, 4185, 1754,\n",
    "         4004, 3380, 3529, 1859, 5953, 2486, 2173,  696, 1380, 1146, 1549, 3550,\n",
    "         4678, 5196, 3248, 1274, 5321, 5632, 5090,  303, 2230, 1095, 1516, 1701,\n",
    "          832, 1320, 4130, 2822,   44]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_emb(sequence, word2vec, vocabulary):\n",
    "    \n",
    "    seq_tokens = []\n",
    "    for key in sequence:\n",
    "        seq_tokens.append(vocabulary['ind2word'][str(key.item())])\n",
    "    \n",
    "    vectorized = []\n",
    "    for word in seq_tokens:\n",
    "        try:\n",
    "            vectorized.append(word2vec[word])\n",
    "        except:\n",
    "            vectorized.append(word2vec['UNK'])\n",
    "    \n",
    "    return np.array(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_cosine(vec1, vec2):\n",
    "    cosine_similarity = np.dot(matutils.unitvec(vec1), matutils.unitvec(vec2))\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reward(target, generated, word2vec, vocabulary):\n",
    "    '''\n",
    "    Calculate the reward for the generated text\n",
    "    '''\n",
    "    target = word2vec_emb(target, word2vec, vocabulary)\n",
    "    generated = word2vec_emb(generated, word2vec, vocabulary)\n",
    "    \n",
    "    print(target)\n",
    "    print('------------------')\n",
    "    print(generated)\n",
    "    reward = similarity_cosine(target.mean(axis=0), generated.mean(axis=0))\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18066406  0.00726318  0.01989746 ... -0.09570312  0.00466919\n",
      "  -0.20800781]\n",
      " [-0.01574707 -0.02832031  0.08349609 ...  0.00686646  0.06103516\n",
      "  -0.1484375 ]\n",
      " [ 0.05981445  0.02380371  0.06738281 ... -0.10986328 -0.00872803\n",
      "   0.03710938]\n",
      " ...\n",
      " [-0.09472656 -0.51171875  0.05810547 ...  0.390625   -0.00338745\n",
      "   0.28125   ]\n",
      " [-0.09472656 -0.51171875  0.05810547 ...  0.390625   -0.00338745\n",
      "   0.28125   ]\n",
      " [-0.09472656 -0.51171875  0.05810547 ...  0.390625   -0.00338745\n",
      "   0.28125   ]]\n",
      "[[ 0.37109375  0.0246582  -0.33203125 ... -0.11767578  0.19335938\n",
      "   0.578125  ]\n",
      " [ 0.00921631  0.09960938 -0.03979492 ...  0.13671875  0.07666016\n",
      "   0.13867188]\n",
      " [-0.10546875 -0.13574219 -0.12402344 ... -0.0088501   0.09863281\n",
      "  -0.29492188]\n",
      " ...\n",
      " [ 0.38085938  0.04174805  0.00180817 ...  0.06225586 -0.23046875\n",
      "  -0.06787109]\n",
      " [-0.22265625 -0.14160156  0.20214844 ... -0.15917969  0.11962891\n",
      "   0.16992188]\n",
      " [ 0.05371094  0.4453125   0.17675781 ...  0.08251953  0.28125\n",
      "  -0.16601562]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5414183"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward(target=target[0], generated=generated[0][1:],\n",
    "          word2vec=word2vec, vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[10]]).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37109375,  0.0246582 , -0.33203125, ..., -0.11767578,\n",
       "         0.19335938,  0.578125  ],\n",
       "       [ 0.00921631,  0.09960938, -0.03979492, ...,  0.13671875,\n",
       "         0.07666016,  0.13867188],\n",
       "       [-0.10546875, -0.13574219, -0.12402344, ..., -0.0088501 ,\n",
       "         0.09863281, -0.29492188],\n",
       "       ...,\n",
       "       [ 0.38085938,  0.04174805,  0.00180817, ...,  0.06225586,\n",
       "        -0.23046875, -0.06787109],\n",
       "       [-0.22265625, -0.14160156,  0.20214844, ..., -0.15917969,\n",
       "         0.11962891,  0.16992188],\n",
       "       [ 0.05371094,  0.4453125 ,  0.17675781, ...,  0.08251953,\n",
       "         0.28125   , -0.16601562]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_emb(generated[0][1:], word2vec, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mse_criterion(torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m34\u001b[39;49m,\u001b[39m4.4\u001b[39;49m,\u001b[39m4\u001b[39;49m]),\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\anest\\anaconda3\\envs\\lgenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\anest\\anaconda3\\envs\\lgenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\anest\\anaconda3\\envs\\lgenv\\lib\\site-packages\\torch\\nn\\functional.py:3281\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3277\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, target):\n\u001b[0;32m   3278\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   3279\u001b[0m         mse_loss, (\u001b[39minput\u001b[39m, target), \u001b[39minput\u001b[39m, target, size_average\u001b[39m=\u001b[39msize_average, reduce\u001b[39m=\u001b[39mreduce, reduction\u001b[39m=\u001b[39mreduction\n\u001b[0;32m   3280\u001b[0m     )\n\u001b[1;32m-> 3281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39;49msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[0;32m   3282\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   3283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3284\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()),\n\u001b[0;32m   3286\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   3287\u001b[0m     )\n\u001b[0;32m   3288\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "mse_criterion(torch.tensor([1,2,34,4.4,4]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = word2vec_emb(generated[0][1:], word2vec, vocabulary)\n",
    "a = torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9195, 0.4132, 0.1352,  ..., 0.2907, 0.8835, 0.4515],\n",
       "        [0.9105, 0.2878, 0.2476,  ..., 0.2693, 0.7531, 0.7952],\n",
       "        [0.0973, 0.4504, 0.8991,  ..., 0.2313, 0.4361, 0.1376],\n",
       "        ...,\n",
       "        [0.4261, 0.0687, 0.6613,  ..., 0.6741, 0.0232, 0.9044],\n",
       "        [0.9803, 0.1017, 0.4276,  ..., 0.8148, 0.9970, 0.1829],\n",
       "        [0.1486, 0.8471, 0.9209,  ..., 0.7939, 0.7246, 0.3602]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()\n",
    "input = torch.rand(40, 300)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_22720\\42727384.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o = mse_criterion(    torch.tensor(a) ,input)\n"
     ]
    }
   ],
   "source": [
    "o = mse_criterion(    torch.tensor(a) ,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_22720\\3427681131.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o = torch.mean(mse_criterion(    torch.tensor(a) ,input), 0)\n"
     ]
    }
   ],
   "source": [
    "o = torch.mean(mse_criterion(    torch.tensor(a) ,input), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m o\u001b[39m.\u001b[39;49mbackward()\n",
      "File \u001b[1;32mc:\\Users\\anest\\anaconda3\\envs\\lgenv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\anest\\anaconda3\\envs\\lgenv\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6194, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge.get_scores(\n",
    "    generated_summary, reference_summary\n",
    ")\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:35:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a2976d16502cff2e17b6fe6532cd24781aa51a139832d843a9c81ff15d5592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
