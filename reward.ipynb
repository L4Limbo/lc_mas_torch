{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import matutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vocabulary and Vectors\n"
     ]
    }
   ],
   "source": [
    "print('Loading Vocabulary and Vectors')\n",
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    'data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "vocabulary = json.load(open('data/processed_data/processed_data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6194, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge.get_scores(\n",
    "    generated_summary, reference_summary\n",
    ")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_emb(sequence, word2vec, vocabulary):\n",
    "    \n",
    "    seq_tokens = []\n",
    "    \n",
    "    for key in sequence:\n",
    "        try:\n",
    "            seq_tokens.append(vocabulary['ind2word'][str(key.item())])\n",
    "        except:\n",
    "            seq_tokens.append(vocabulary['ind2word'][list(\n",
    "                vocabulary['ind2word'].keys())[-1]])\n",
    "    \n",
    "    vectorized = []\n",
    "    for word in seq_tokens:\n",
    "        try:\n",
    "            vectorized.append(word2vec[word])\n",
    "        except:\n",
    "            vectorized.append(np.zeros(300,))\n",
    "    \n",
    "    return np.array(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_cosine(vec1, vec2):\n",
    "    cosine_similarity = np.dot(matutils.unitvec(vec1), matutils.unitvec(vec2))\n",
    "    print(cosine_similarity)\n",
    "    print(spatial.distance.cosine(vec1, vec2))\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(target, generated, word2vec, vocabulary):\n",
    "    '''\n",
    "    Calculate the reward for the generated text\n",
    "    '''\n",
    "    target = word2vec_emb(target, word2vec, vocabulary)\n",
    "    generated = word2vec_emb(generated, word2vec, vocabulary)\n",
    "    \n",
    "    reward = similarity_cosine(target.mean(axis=0), generated.mean(axis=0))\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = torch.tensor([[6100, 4948, 6066, 1336, 4264, 4093,   37, 3343, 2467, 5527, 3396, 4326,\n",
    "          219, 5560, 5845, 1464, 3149, 2805, 4154, 1899, 5642]])\n",
    "\n",
    "question = torch.tensor([[6100, 2440, 5128, 5570,  511, 2483, 4828, 3564,  282, 3869, 2614,    7,\n",
    "         4783, 4595, 5613, 1385, 6032, 4369,  286, 2259, 1900]])\n",
    "\n",
    "summary = torch.tensor([[6100, 5955, 2642, 6021, 1982, 3081, 3554, 3802, 4577, 5298, 5555, 1110,\n",
    "         4515, 2661, 2299, 4606, 4956, 4007, 3281, 2625, 2206, 4335, 2730, 2925,\n",
    "         4523, 1231, 4269,  427,  861, 4104, 2630, 2499, 5430, 4043, 5146, 4595,\n",
    "         3772, 5545, 4852, 3325, 4324]])\n",
    "\n",
    "gtSummary = torch.tensor([[405,  333,  880,  188,  624,  194,  996,  293,  244, 6099, 3275,   99,\n",
    "           25,  244,  754,  636,  936, 1461, 3653,   51,   55,   56,   57,    1,\n",
    "           58,    1,   59,    1,   60,   52,  244, 1367, 6099, 1368, 3654, 2424,\n",
    "           76,   51, 3655,   52]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565139467498903\n",
      "0.6523351061715779\n"
     ]
    }
   ],
   "source": [
    "# torch.cat((answer[0], question[0]))\n",
    "print(reward(target=torch.cat((answer[0], question[0])), generated=summary[0], word2vec=word2vec, vocabulary=vocabulary))\n",
    "print(reward(target=gtSummary[0], generated=summary[0], word2vec=word2vec, vocabulary=vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "def rouge_scores(target, generated, word2vec, vocabulary):\n",
    "    rouge = Rouge()\n",
    "    tar = []\n",
    "    ref = []\n",
    "\n",
    "    for key in target:\n",
    "        try:\n",
    "            if vocabulary['ind2word'][str(key.item())] !='UNK':\n",
    "                tar.append(vocabulary['ind2word'][str(key.item())])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for key in generated:\n",
    "        try:\n",
    "            if vocabulary['ind2word'][str(key.item())] !='UNK':\n",
    "                ref.append(vocabulary['ind2word'][str(key.item())])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return rouge.get_scores(' '.join(ref), ' '.join(tar), avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 visible one-half calling retinal open-angle missing elbows street hopeless absolutely S loss Depakene TEE acid minimal double recurrences opposite Cutting tends efforts settings hepatitis reflexes heart-lung Name 1 Oxygen endoscopy if Autonomic beat companies cervical Nonne-Milroy separates Fragile osteochondrodysplasias abnormally\n",
      "- - - - - - \n",
      "40 running electrical Recurrent barley amyloid Rapid senses containers Evidence Hospitalization testing Joseph FODMAP x-rays fasting coated Southeast psoralen Sharing natural G pacing mouthwashes Rasagiline While psychiatric resistance new lights relieving babies Involved specially firm beat relationships instability cookies colloidal mechanisms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.025, 'p': 0.025, 'f': 0.024999995000001003},\n",
       " 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       " 'rouge-l': {'r': 0.025, 'p': 0.025, 'f': 0.024999995000001003}}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores(torch.cat((answer[0], question[0])), summary[0], word2vec, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.7142857142857143, 'p': 1.0, 'f': 0.8333333284722222},\n",
       " 'rouge-2': {'r': 0.6666666666666666, 'p': 1.0, 'f': 0.7999999952000001},\n",
       " 'rouge-l': {'r': 0.7142857142857143, 'p': 1.0, 'f': 0.8333333284722222}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rouge().get_scores('I go to the beach','I go to the beach every data', avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import lc_options\n",
    "from utils import lc_utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json file: data/processed_data/processed_data.json\n",
      "Vocab size with <START>, <END>: 4846\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'inputJson': \"data/processed_data/processed_data.json\",\n",
    "    'useGPU': False,\n",
    "    \n",
    "    # A-Bot checkpoint\n",
    "    'startFrom': \"./checkpoints/exp_5/abot_ep_30.vd\",\n",
    "    \n",
    "    # Q-Bot checkpoint should given if interactive dialog is required\n",
    "    'qstartFrom': \"./checkpoints/exp_5/qbot_ep_30.vd\",\n",
    "    \n",
    "    'beamSize': 5,\n",
    "}\n",
    "\n",
    "# RNG seed\n",
    "manualSeed = 1597\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if params['useGPU']:\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "print('Loading json file: ' + params['inputJson'])\n",
    "with open(params['inputJson'], 'r') as fileId:\n",
    "    info = json.load(fileId)\n",
    "\n",
    "wordCount = len(info['word2ind'])\n",
    "# Add <START> and <END> to vocabulary\n",
    "info['word2ind']['<START>'] = wordCount + 1\n",
    "info['word2ind']['<END>'] = wordCount + 2\n",
    "startToken = info['word2ind']['<START>']\n",
    "endToken = info['word2ind']['<END>']\n",
    "# Padding token is at index 0\n",
    "vocabSize = wordCount + 3\n",
    "print('Vocab size with <START>, <END>: %d' % vocabSize)\n",
    "\n",
    "# Construct the reverse map\n",
    "info['ind2word'] = {\n",
    "    int(ind): word\n",
    "    for word, ind in info['word2ind'].items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(params, agent='abot'):\n",
    "    # should be everything used in encoderParam, decoderParam below\n",
    "    encoderOptions = [\n",
    "        'encoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'useHistory', 'numRounds', 'dropout'\n",
    "    ]\n",
    "    decoderOptions = [\n",
    "        'decoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'dropout'\n",
    "    ]\n",
    "    modelOptions = encoderOptions + decoderOptions\n",
    "\n",
    "    mdict = None\n",
    "    gpuFlag = params['useGPU']\n",
    "    startArg = 'startFrom' if agent == 'abot' else 'qstartFrom'\n",
    "    assert params[startArg], \"Need checkpoint for {}\".format(agent)\n",
    "\n",
    "    if params[startArg]:\n",
    "        print('Loading model (weights and config) from {}'.format(\n",
    "            params[startArg]))\n",
    "\n",
    "        if gpuFlag:\n",
    "            mdict = torch.load(params[startArg])\n",
    "        else:\n",
    "            mdict = torch.load(params[startArg],\n",
    "                map_location=lambda storage, location: storage)\n",
    "\n",
    "        # Model options is a union of standard model options defined\n",
    "        # above and parameters loaded from checkpoint\n",
    "        modelOptions = list(set(modelOptions).union(set(mdict['params'])))\n",
    "        for opt in modelOptions:\n",
    "            if opt not in params:\n",
    "                params[opt] = mdict['params'][opt]\n",
    "\n",
    "            elif params[opt] != mdict['params'][opt]:\n",
    "                # Parameters are not overwritten from checkpoint\n",
    "                pass\n",
    "\n",
    "    # Initialize model class\n",
    "    encoderParam = {k: params[k] for k in encoderOptions}\n",
    "    decoderParam = {k: params[k] for k in decoderOptions}\n",
    "\n",
    "    encoderParam['startToken'] = encoderParam['vocabSize'] - 2\n",
    "    encoderParam['endToken'] = encoderParam['vocabSize'] - 1\n",
    "    decoderParam['startToken'] = decoderParam['vocabSize'] - 2\n",
    "    decoderParam['endToken'] = decoderParam['vocabSize'] - 1\n",
    "\n",
    "    if agent == 'abot':\n",
    "        encoderParam['type'] = params['encoder']\n",
    "        decoderParam['type'] = params['decoder']\n",
    "        encoderParam['isAnswerer'] = True\n",
    "        from lc.models.lc_answerer import Answerer\n",
    "        model = Answerer(encoderParam, decoderParam)\n",
    "\n",
    "    elif agent == 'qbot':\n",
    "        encoderParam['type'] = params['qencoder']\n",
    "        decoderParam['type'] = params['qdecoder']\n",
    "        encoderParam['isAnswerer'] = False\n",
    "        from lc.models.lc_questioner import Questioner\n",
    "        model = Questioner(\n",
    "            encoderParam,\n",
    "            decoderParam,\n",
    "            summFeatureSize=40)\n",
    "\n",
    "    # if params['useGPU']:\n",
    "    #     model.cuda()\n",
    "\n",
    "    if mdict:\n",
    "        model.load_state_dict(mdict['model'])\n",
    "        \n",
    "    print(\"Loaded agent {}\".format(agent))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "aBot = None\n",
    "qBot = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (weights and config) from ./checkpoints/exp_5/abot_ep_30.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/exp_5/qbot_ep_30.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n"
     ]
    }
   ],
   "source": [
    "# load aBot\n",
    "if params['startFrom']:\n",
    "    aBot = loadModel(params, 'abot')\n",
    "    assert aBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    aBot.eval()\n",
    "    \n",
    "# load qBot\n",
    "if params['qstartFrom']:\n",
    "    qBot = loadModel(params, 'qbot')\n",
    "    assert qBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    qBot.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'Smoking and surgery Surgery - quitting smoking Surgery - quitting tobacco Wound healing - smoking Summary Quitting smoking and other tobacco products before surgery can improve your recovery and outcome after surgery. Most people who successfully quit smoking have tried and failed many times. DO NOT give up. Learning from your past tries can help you succeed. There Are Many Reasons to Quit Smoking Tar, nicotine, and other chemicals from smoking can increase your risk of many health problems. These include heart and blood vessel problems, such as: Blood clots and aneurysms in the brain, which can lead to strokes Coronary artery disease, including chest pain (angina) and heart attacks High blood pressure Poor blood supply to the legs Problems with erections Smoking also increases your risk for different types of cancer, including cancer of the: Lungs Mouth Larynx Esophagus Bladder Kidneys Pancreas Cervix Smoking also leads to lung problems, such as emphysema and chronic bronchitis, and makes asthma harder to control. Some smokers switch to smokeless tobacco instead of quitting tobacco completely. But using smokeless tobacco still carries health risks, such as: Developing mouth or nasal cancer Gum problems, tooth wear, and cavities Worsening high blood pressure and chest pain How Smoking Affects Surgery Smokers who have surgery have a higher chance than nonsmokers of blood clots forming in their legs. These clots may travel to and damage the lungs. Smoking decreases the amount of oxygen that reaches the cells in your surgical wound. As a result, your wound may heal more slowly and is more likely to become infected. All smokers carry an increased risk for heart and lung problems. Even when your surgery goes smoothly, smoking causes your body, heart, and lungs to work harder than if you did not smoke. Making the Decision to Quit Most doctors will tell you to stop using cigarettes and tobacco at least 4 weeks before your surgery. Stretching the time between quitting smoking and your surgery out to at least 10 weeks can decrease your risk of problems even more. Like any addiction, quitting tobacco is difficult. There are many ways to quit smoking and many resources to help you, such as: Family members, friends, and coworkers may be supportive or encouraging. Talk to your doctor about medicines, such as nicotine replacement and prescription medicines. If you join smoking cessation programs, you have a much better chance of success. Such programs are offered by hospitals, health departments, community centers, and work sites. Using nicotine gum around the time of surgery is not encouraged. The nicotine will still interfere with the healing of your surgical wound and have the same effect on your general health as using cigarettes and tobacco. Review Date 9/17/2016 Updated by: Debra G. Wechter, MD, FACS, general surgery practice specializing in breast cancer, Virginia Mason Medical Center, Seattle, WA. Also reviewed by David Zieve, MD, MHA, Isla Ogilvie, PhD, and the A.D.A.M. Editorial team. '\n",
    "docs = doc\n",
    "summary = 'Nicotine use can have many different effects on the body. It can: - Decrease the appetite; fear of weight gain makes some people unwilling to stop smoking - Boost mood, give people a sense of well-being, and possibly even relieve minor depression - Increase activity in the intestines - Create more saliva and phlegm - Increase the heart rate by around 10 to 20 beats per minute - Increase blood pressure by 5 to 10 mm Hg - Possibly cause sweating, nausea, and diarrhea - Stimulate memory and alertness; people who use tobacco often depend on it to help them accomplish certain tasks and perform well Symptoms of nicotine withdrawal appear within 2 to 3 hours after you last use tobacco.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_map = lambda words: np.array([info['word2ind'].get(word, info['word2ind']['UNK']) \n",
    "                                  for word in words], dtype='int64')\n",
    "\n",
    "tokenize = lambda string: ['<START>'] + word_tokenize(string) + ['<END>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process document\n",
    "doc_tokens = tokenize(doc)\n",
    "doc = ind_map(doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4844, 4843,   32,  496, 4843, 4843,  313,  314, 4843, 4843,  313,\n",
       "       1200, 4843, 2374, 4843,  314, 4843, 4843,  314,   32,  242, 1200,\n",
       "        479,  750,  496,  104, 1372,  339,  171,   32, 4307,  486,  496,\n",
       "       4843, 4843,   36,  332, 2001, 1375,  314,   21, 1936,   32, 2832,\n",
       "         23,  844, 4843, 4843, 4843,  604,  374, 4843, 4843,   56,  339,\n",
       "       1236, 4843,  104,  175,  107, 4308, 4843, 4843, 4843, 4843, 4843,\n",
       "          5, 4843, 4843, 4843, 4843, 1198, 4843,   32,  242,  515,   56,\n",
       "        314,  104,  755,  339,  303,   41,   23,  535,  178, 4843, 4843,\n",
       "        907,  687,   32,   93, 1245,  178, 4843,  348,  102, 4843, 4843,\n",
       "        712,   32, 4843,   75,   57,  320, 4843,  181,  104,  125,    5,\n",
       "        307, 4843,  780,  110, 4843,  931,  129,  498, 4843, 1246, 4843,\n",
       "         32,  687,  643, 4843,   93,  317, 4843,   93, 1248,    5,   57,\n",
       "       1249, 4843,   15, 4843, 4843,  162, 1211,  339,  303,   12,  420,\n",
       "        331,   41, 1229, 4843,  931, 1229,   41,   57, 4843, 4843, 4843,\n",
       "       4843, 4843, 4843, 4843, 4843, 4843, 4843,  162, 1252,    5,  713,\n",
       "        178, 4843,  348,  102, 1253,   32,  109, 1254, 4843,   32,  404,\n",
       "         98,  702,    5,  385, 4843, 4843, 1255, 1256,    5, 1257, 1200,\n",
       "       1258,   41,  313, 1200, 1259, 4843, 4843,  334, 1257, 1200,  164,\n",
       "       2738,  535, 1092, 4843,  348,  102, 4843, 4843,  863,  118,  995,\n",
       "       1229, 4843,  178, 4843, 1577,  542, 4843,   32,  868, 4843,  316,\n",
       "         93,  317,   32,  129,  498, 4843, 4843, 4843, 4843, 4843,  332,\n",
       "         21,  496,   21,   39, 1455,  169,  746, 4257,   41,   93,  712,\n",
       "       3542,   75,  225, 1249, 4843, 4843,  712,  305, 2138,    5,   32,\n",
       "        241,   57,  121, 4843, 4843, 1328,   57,  538,   41,  690,   25,\n",
       "       3783,   57,   71,   75,  339,  786,  490, 4843, 4843,   39, 1425,\n",
       "       4843,  339,  490,  305,  481,  431, 1290,   32,    9,  431,  446,\n",
       "          5,  144,  557, 4843, 4843, 1255,  699,   43, 1721,  303,   12,\n",
       "        687,   32,  713,  178, 4843, 4843,   94,  339,  496, 1929, 4843,\n",
       "       4843,  314,   46,  339,   70, 4843,  687, 4843,   32,  121,    5,\n",
       "        701,  702,  746,    7,  107, 4843,   18, 1207, 4843, 4843,   57,\n",
       "       4843,    5, 4843, 4843,  101,  221,  357,  107,    5,  333,  334,\n",
       "       4198,   32, 1200,  192, 2318, 4843,  484,  750,  339,  496, 4843,\n",
       "       4843,   57,  189, 4843,  313,  314,   32,  339,  496,  588,    5,\n",
       "        192, 2318, 4843,  484,  104,  342,  339,  303,   41,  178, 1005,\n",
       "        431, 4843, 4843,   10, 4256, 4843,  313, 1200,    9,  646, 4843,\n",
       "       4843,   37,   23, 1265,    5, 1375,  314,   32,   23, 1818,    5,\n",
       "        175,  107, 4843,  348,  102, 4843, 4843, 3336, 4843, 1501, 4843,\n",
       "         32, 3836,  305,  105, 2679,  118, 4309, 4843, 4843,    5,  339,\n",
       "        340,  261,  718, 4843,  348,  102, 1198,  988,   32, 1164,  718,\n",
       "       4843, 4843,  107, 3193,  314, 4288, 2444, 4843,  107,   21,   39,\n",
       "        412, 1269,  169,   41, 1049, 4843, 4843, 2444,   37, 3388,  133,\n",
       "       4285, 4843,  535, 4310, 4843, 3745, 1715, 4843,   32,  701, 4311,\n",
       "       4843, 4843, 1198,  866, 2057,   57,  189,   41,  496,    9,   18,\n",
       "       4312, 4843, 4843, 1198,  221,  164,  644,   15,   57, 2374,   41,\n",
       "        339,  786,  490,   32,   21,   57, 4843, 1329,  289,  339, 1538,\n",
       "        535,  102,  334, 4198,   32, 1200, 4843, 4843, 4843, 4843, 4843,\n",
       "        133, 4843, 4843, 4843, 4843, 4843, 4843, 4843, 4843, 4843, 1538,\n",
       "        496, 3292, 3618,   75,  900, 1229, 4843, 4843, 4843, 4843, 4843,\n",
       "       4843, 4843, 4843, 4843, 4843, 4843, 1828,  133, 4843, 4843, 4843,\n",
       "       4843, 4843, 4843, 4843, 4843, 4843, 4843, 4843, 4843,   32,   57,\n",
       "       4843, 4843, 4843, 1513, 4843, 4845], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for converting tensors to words\n",
    "to_str_pred = lambda w, l: str(\" \".join([info['ind2word'][x] for x in list( filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy()))][:l.data.cpu()[0]]))[8:]\n",
    "to_str_gt = lambda w: str(\" \".join([info['ind2word'][x] for x in filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy())]))[8:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_map(tensor):\n",
    "    return Variable(tensor.unsqueeze(0), volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_17476\\881476409.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(tensor.unsqueeze(0), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "doc_tensor = var_map(torch.from_numpy(doc))\n",
    "doc_lens = var_map(torch.LongTensor([len(doc)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END>\n",
      "A1:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt trouble \n",
      "Q2:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END> <END>\n",
      "A2:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q3:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A3:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q4:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A4:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q5:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A5:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q6:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A6:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q7:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A7:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q8:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A8:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q9:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A9:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "Q10:  how to prevent atherosclerosis ? <END> <END> <END> <END> <END> <END>\n",
      "A10:  atherosclerosis prevention taking action to prevent cancer if you smoke now in you smoke now therapy is adopt troubl\n",
      "----------------------------------------\n",
      "Summary:  always treatment pumps blood pressure picks oxygen blood returns left side heart pumped rest body small arteries UNK abnormality UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK U\n"
     ]
    }
   ],
   "source": [
    "if aBot:\n",
    "    aBot.eval(), aBot.reset()\n",
    "    aBot.observe(\n",
    "        -1, document=doc_tensor, documentLens=doc_lens)\n",
    "    \n",
    "if qBot:\n",
    "    qBot.train(), qBot.reset()\n",
    "    qBot.observe(-1, document=doc_tensor, documentLens=doc_lens)\n",
    "\n",
    "numRounds = 10\n",
    "beamSize = 5\n",
    "summ, summLens = qBot.predictSummary(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "# print('----------------------------------------')\n",
    "# print(\"Summary: \", to_str_gt(summ[0]))    \n",
    "for round in range(numRounds):\n",
    "    questions, quesLens = qBot.forwardDecode(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "    qBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "    aBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "    \n",
    "    \n",
    "    answers, ansLens = aBot.forwardDecode(\n",
    "        beamSize=beamSize, inference='greedy')\n",
    "    aBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    qBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    \n",
    "    # Printing\n",
    "    print(\"Q%d: \"%(round+1), to_str_gt(questions[0]))\n",
    "    print(\"A%d: \"%(round+1), to_str_gt(answers[0]))\n",
    "    summ, summLens = qBot.predictSummary(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "    # print('----------------------------------------')\n",
    "    # print(\"Summary: \", to_str_gt(summ[0]))\n",
    "\n",
    "\n",
    "summ, summLens = qBot.predictSummary(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "print('----------------------------------------')\n",
    "print(\"Summary: \", to_str_gt(summ[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inherited metabolic disease caused harmful buildup lipids fatty UNK oils acids various cells tissues body affected children appear develop normally age months symptoms begin include progressive loss mental ability dementia blindness increased UNK reflex noise progressive loss hearing leading de'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_str_gt(summ[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.05405405405405406,\n",
       "  'p': 0.02197802197802198,\n",
       "  'f': 0.03124999588989312},\n",
       " 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       " 'rouge-l': {'r': 0.05405405405405406,\n",
       "  'p': 0.02197802197802198,\n",
       "  'f': 0.03124999588989312}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rouge().get_scores(summary, to_str_gt(summ[0]), avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.01060070671378092,\n",
       "  'p': 0.08108108108108109,\n",
       "  'f': 0.018749997954883038},\n",
       " 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       " 'rouge-l': {'r': 0.01060070671378092,\n",
       "  'p': 0.08108108108108109,\n",
       "  'f': 0.018749997954883038}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rouge().get_scores(to_str_gt(summ[0]), docs, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include\n",
      "cells\n",
      "increased\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for word in docs.split(' '):\n",
    "    if word in to_str_gt(summ[0]).split(' '):\n",
    "        print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a2976d16502cff2e17b6fe6532cd24781aa51a139832d843a9c81ff15d5592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
