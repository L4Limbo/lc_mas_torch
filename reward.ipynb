{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import matutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vocabulary and Vectors\n"
     ]
    }
   ],
   "source": [
    "print('Loading Vocabulary and Vectors')\n",
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    'data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "vocabulary = json.load(open('data/processed_data/processed_data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6194, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge.get_scores(\n",
    "    generated_summary, reference_summary\n",
    ")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_emb(sequence, word2vec, vocabulary):\n",
    "    \n",
    "    seq_tokens = []\n",
    "    \n",
    "    for key in sequence:\n",
    "        try:\n",
    "            seq_tokens.append(vocabulary['ind2word'][str(key.item())])\n",
    "        except:\n",
    "            seq_tokens.append(vocabulary['ind2word'][list(\n",
    "                vocabulary['ind2word'].keys())[-1]])\n",
    "    \n",
    "    vectorized = []\n",
    "    for word in seq_tokens:\n",
    "        try:\n",
    "            vectorized.append(word2vec[word])\n",
    "        except:\n",
    "            vectorized.append(np.zeros(300,))\n",
    "    \n",
    "    return np.array(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_cosine(vec1, vec2):\n",
    "    cosine_similarity = np.dot(matutils.unitvec(vec1), matutils.unitvec(vec2))\n",
    "    print(cosine_similarity)\n",
    "    print(spatial.distance.cosine(vec1, vec2))\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(target, generated, word2vec, vocabulary):\n",
    "    '''\n",
    "    Calculate the reward for the generated text\n",
    "    '''\n",
    "    target = word2vec_emb(target, word2vec, vocabulary)\n",
    "    generated = word2vec_emb(generated, word2vec, vocabulary)\n",
    "    \n",
    "    reward = similarity_cosine(target.mean(axis=0), generated.mean(axis=0))\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = torch.tensor([[6100, 4948, 6066, 1336, 4264, 4093,   37, 3343, 2467, 5527, 3396, 4326,\n",
    "          219, 5560, 5845, 1464, 3149, 2805, 4154, 1899, 5642]])\n",
    "\n",
    "question = torch.tensor([[6100, 2440, 5128, 5570,  511, 2483, 4828, 3564,  282, 3869, 2614,    7,\n",
    "         4783, 4595, 5613, 1385, 6032, 4369,  286, 2259, 1900]])\n",
    "\n",
    "summary = torch.tensor([[6100, 5955, 2642, 6021, 1982, 3081, 3554, 3802, 4577, 5298, 5555, 1110,\n",
    "         4515, 2661, 2299, 4606, 4956, 4007, 3281, 2625, 2206, 4335, 2730, 2925,\n",
    "         4523, 1231, 4269,  427,  861, 4104, 2630, 2499, 5430, 4043, 5146, 4595,\n",
    "         3772, 5545, 4852, 3325, 4324]])\n",
    "\n",
    "gtSummary = torch.tensor([[405,  333,  880,  188,  624,  194,  996,  293,  244, 6099, 3275,   99,\n",
    "           25,  244,  754,  636,  936, 1461, 3653,   51,   55,   56,   57,    1,\n",
    "           58,    1,   59,    1,   60,   52,  244, 1367, 6099, 1368, 3654, 2424,\n",
    "           76,   51, 3655,   52]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565139467498903\n",
      "0.6523351061715779\n"
     ]
    }
   ],
   "source": [
    "# torch.cat((answer[0], question[0]))\n",
    "print(reward(target=torch.cat((answer[0], question[0])), generated=summary[0], word2vec=word2vec, vocabulary=vocabulary))\n",
    "print(reward(target=gtSummary[0], generated=summary[0], word2vec=word2vec, vocabulary=vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "def rouge_scores(target, generated, word2vec, vocabulary):\n",
    "    rouge = Rouge()\n",
    "    tar = []\n",
    "    ref = []\n",
    "\n",
    "    for key in target:\n",
    "        try:\n",
    "            if vocabulary['ind2word'][str(key.item())] !='UNK':\n",
    "                tar.append(vocabulary['ind2word'][str(key.item())])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for key in generated:\n",
    "        try:\n",
    "            if vocabulary['ind2word'][str(key.item())] !='UNK':\n",
    "                ref.append(vocabulary['ind2word'][str(key.item())])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return rouge.get_scores(' '.join(ref), ' '.join(tar), avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 visible one-half calling retinal open-angle missing elbows street hopeless absolutely S loss Depakene TEE acid minimal double recurrences opposite Cutting tends efforts settings hepatitis reflexes heart-lung Name 1 Oxygen endoscopy if Autonomic beat companies cervical Nonne-Milroy separates Fragile osteochondrodysplasias abnormally\n",
      "- - - - - - \n",
      "40 running electrical Recurrent barley amyloid Rapid senses containers Evidence Hospitalization testing Joseph FODMAP x-rays fasting coated Southeast psoralen Sharing natural G pacing mouthwashes Rasagiline While psychiatric resistance new lights relieving babies Involved specially firm beat relationships instability cookies colloidal mechanisms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.025, 'p': 0.025, 'f': 0.024999995000001003},\n",
       " 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0},\n",
       " 'rouge-l': {'r': 0.025, 'p': 0.025, 'f': 0.024999995000001003}}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores(torch.cat((answer[0], question[0])), summary[0], word2vec, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.7142857142857143, 'p': 1.0, 'f': 0.8333333284722222},\n",
       " 'rouge-2': {'r': 0.6666666666666666, 'p': 1.0, 'f': 0.7999999952000001},\n",
       " 'rouge-l': {'r': 0.7142857142857143, 'p': 1.0, 'f': 0.8333333284722222}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rouge().get_scores('I go to the beach','I go to the beach every data', avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import lc_options\n",
    "from utils import lc_utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json file: data/processed_data/processed_data.json\n",
      "Vocab size with <START>, <END>: 6055\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'inputJson': \"data/processed_data/processed_data.json\",\n",
    "    'useGPU': False,\n",
    "    \n",
    "    # A-Bot checkpoint\n",
    "    'startFrom': \"./checkpoints/exp_4/abot_ep_59.vd\",\n",
    "    \n",
    "    # Q-Bot checkpoint should given if interactive dialog is required\n",
    "    'qstartFrom': \"./checkpoints/exp_4/qbot_ep_59.vd\",\n",
    "    \n",
    "    'beamSize': 5,\n",
    "}\n",
    "\n",
    "# RNG seed\n",
    "manualSeed = 1597\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if params['useGPU']:\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "print('Loading json file: ' + params['inputJson'])\n",
    "with open(params['inputJson'], 'r') as fileId:\n",
    "    info = json.load(fileId)\n",
    "\n",
    "wordCount = len(info['word2ind'])\n",
    "# Add <START> and <END> to vocabulary\n",
    "info['word2ind']['<START>'] = wordCount + 1\n",
    "info['word2ind']['<END>'] = wordCount + 2\n",
    "startToken = info['word2ind']['<START>']\n",
    "endToken = info['word2ind']['<END>']\n",
    "# Padding token is at index 0\n",
    "vocabSize = wordCount + 3\n",
    "print('Vocab size with <START>, <END>: %d' % vocabSize)\n",
    "\n",
    "# Construct the reverse map\n",
    "info['ind2word'] = {\n",
    "    int(ind): word\n",
    "    for word, ind in info['word2ind'].items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(params, agent='abot'):\n",
    "    # should be everything used in encoderParam, decoderParam below\n",
    "    encoderOptions = [\n",
    "        'encoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'useHistory', 'numRounds', 'dropout'\n",
    "    ]\n",
    "    decoderOptions = [\n",
    "        'decoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'dropout'\n",
    "    ]\n",
    "    modelOptions = encoderOptions + decoderOptions\n",
    "\n",
    "    mdict = None\n",
    "    gpuFlag = params['useGPU']\n",
    "    startArg = 'startFrom' if agent == 'abot' else 'qstartFrom'\n",
    "    assert params[startArg], \"Need checkpoint for {}\".format(agent)\n",
    "\n",
    "    if params[startArg]:\n",
    "        print('Loading model (weights and config) from {}'.format(\n",
    "            params[startArg]))\n",
    "\n",
    "        if gpuFlag:\n",
    "            mdict = torch.load(params[startArg])\n",
    "        else:\n",
    "            mdict = torch.load(params[startArg],\n",
    "                map_location=lambda storage, location: storage)\n",
    "\n",
    "        # Model options is a union of standard model options defined\n",
    "        # above and parameters loaded from checkpoint\n",
    "        modelOptions = list(set(modelOptions).union(set(mdict['params'])))\n",
    "        for opt in modelOptions:\n",
    "            if opt not in params:\n",
    "                params[opt] = mdict['params'][opt]\n",
    "\n",
    "            elif params[opt] != mdict['params'][opt]:\n",
    "                # Parameters are not overwritten from checkpoint\n",
    "                pass\n",
    "\n",
    "    # Initialize model class\n",
    "    encoderParam = {k: params[k] for k in encoderOptions}\n",
    "    decoderParam = {k: params[k] for k in decoderOptions}\n",
    "\n",
    "    encoderParam['startToken'] = encoderParam['vocabSize'] - 2\n",
    "    encoderParam['endToken'] = encoderParam['vocabSize'] - 1\n",
    "    decoderParam['startToken'] = decoderParam['vocabSize'] - 2\n",
    "    decoderParam['endToken'] = decoderParam['vocabSize'] - 1\n",
    "\n",
    "    if agent == 'abot':\n",
    "        encoderParam['type'] = params['encoder']\n",
    "        decoderParam['type'] = params['decoder']\n",
    "        encoderParam['isAnswerer'] = True\n",
    "        from lc.models.lc_answerer import Answerer\n",
    "        model = Answerer(encoderParam, decoderParam)\n",
    "\n",
    "    elif agent == 'qbot':\n",
    "        encoderParam['type'] = params['qencoder']\n",
    "        decoderParam['type'] = params['qdecoder']\n",
    "        encoderParam['isAnswerer'] = False\n",
    "        from lc.models.lc_questioner import Questioner\n",
    "        model = Questioner(\n",
    "            encoderParam,\n",
    "            decoderParam,\n",
    "            summFeatureSize=40)\n",
    "\n",
    "    # if params['useGPU']:\n",
    "    #     model.cuda()\n",
    "\n",
    "    if mdict:\n",
    "        model.load_state_dict(mdict['model'])\n",
    "        \n",
    "    print(\"Loaded agent {}\".format(agent))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aBot = None\n",
    "qBot = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (weights and config) from ./checkpoints/exp_4/abot_ep_59.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/exp_4/qbot_ep_59.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n"
     ]
    }
   ],
   "source": [
    "# load aBot\n",
    "if params['startFrom']:\n",
    "    aBot = loadModel(params, 'abot')\n",
    "    assert aBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    aBot.eval()\n",
    "    \n",
    "# load qBot\n",
    "if params['qstartFrom']:\n",
    "    qBot = loadModel(params, 'qbot')\n",
    "    assert qBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    qBot.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'Smoking and surgery Surgery - quitting smoking Surgery - quitting tobacco Wound healing - smoking Summary Quitting smoking and other tobacco products before surgery can improve your recovery and outcome after surgery. Most people who successfully quit smoking have tried and failed many times. DO NOT give up. Learning from your past tries can help you succeed. There Are Many Reasons to Quit Smoking Tar, nicotine, and other chemicals from smoking can increase your risk of many health problems. These include heart and blood vessel problems, such as: Blood clots and aneurysms in the brain, which can lead to strokes Coronary artery disease, including chest pain (angina) and heart attacks High blood pressure Poor blood supply to the legs Problems with erections Smoking also increases your risk for different types of cancer, including cancer of the: Lungs Mouth Larynx Esophagus Bladder Kidneys Pancreas Cervix Smoking also leads to lung problems, such as emphysema and chronic bronchitis, and makes asthma harder to control. Some smokers switch to smokeless tobacco instead of quitting tobacco completely. But using smokeless tobacco still carries health risks, such as: Developing mouth or nasal cancer Gum problems, tooth wear, and cavities Worsening high blood pressure and chest pain How Smoking Affects Surgery Smokers who have surgery have a higher chance than nonsmokers of blood clots forming in their legs. These clots may travel to and damage the lungs. Smoking decreases the amount of oxygen that reaches the cells in your surgical wound. As a result, your wound may heal more slowly and is more likely to become infected. All smokers carry an increased risk for heart and lung problems. Even when your surgery goes smoothly, smoking causes your body, heart, and lungs to work harder than if you did not smoke. Making the Decision to Quit Most doctors will tell you to stop using cigarettes and tobacco at least 4 weeks before your surgery. Stretching the time between quitting smoking and your surgery out to at least 10 weeks can decrease your risk of problems even more. Like any addiction, quitting tobacco is difficult. There are many ways to quit smoking and many resources to help you, such as: Family members, friends, and coworkers may be supportive or encouraging. Talk to your doctor about medicines, such as nicotine replacement and prescription medicines. If you join smoking cessation programs, you have a much better chance of success. Such programs are offered by hospitals, health departments, community centers, and work sites. Using nicotine gum around the time of surgery is not encouraged. The nicotine will still interfere with the healing of your surgical wound and have the same effect on your general health as using cigarettes and tobacco. Review Date 9/17/2016 Updated by: Debra G. Wechter, MD, FACS, general surgery practice specializing in breast cancer, Virginia Mason Medical Center, Seattle, WA. Also reviewed by David Zieve, MD, MHA, Isla Ogilvie, PhD, and the A.D.A.M. Editorial team. '\n",
    "docs = doc\n",
    "summary = 'Nicotine use can have many different effects on the body. It can: - Decrease the appetite; fear of weight gain makes some people unwilling to stop smoking - Boost mood, give people a sense of well-being, and possibly even relieve minor depression - Increase activity in the intestines - Create more saliva and phlegm - Increase the heart rate by around 10 to 20 beats per minute - Increase blood pressure by 5 to 10 mm Hg - Possibly cause sweating, nausea, and diarrhea - Stimulate memory and alertness; people who use tobacco often depend on it to help them accomplish certain tasks and perform well Symptoms of nicotine withdrawal appear within 2 to 3 hours after you last use tobacco.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_map = lambda words: np.array([info['word2ind'].get(word, info['word2ind']['UNK']) \n",
    "                                  for word in words], dtype='int64')\n",
    "\n",
    "tokenize = lambda string: ['<START>'] + word_tokenize(string) + ['<END>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process document\n",
    "doc_tokens = tokenize(doc)\n",
    "doc = ind_map(doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6053,  883,   32,  325, 1193,  409,  902,  871, 1193,  409,  902,\n",
       "        834, 6052, 1954,  409,  871,  654, 2959,  871,   32,  402,  834,\n",
       "        306,  515,  325,  203, 1024,  235,  132,   32, 5264,  315,  325,\n",
       "         42,  301,   34,  397, 3457, 1029,  871,   21, 1052,   32, 3982,\n",
       "         23,  556,   42, 2490, 2491, 1112, 1037,   42, 1555,   61,  235,\n",
       "       2595, 6052,  203,  138,  244, 5265,   42,  600, 4154,  346, 6052,\n",
       "          5, 1028,  883, 6052,    1,  830,    1,   32,  402,  355,   61,\n",
       "        871,  203,  522,  235,  523,   39,   23,  391,  142,   42,  833,\n",
       "        621,  524,   32,   99,  872,  142,    1,  249,  250,  194,  873,\n",
       "        874,   32, 6052,   80,   62,  683,    1,  145,  203,  571,    5,\n",
       "        875,  876,  877,  278,    1,  649,  575,  328,   50,  878,   52,\n",
       "         32,  524,  460,  521,   99,  754,  879,   99,  880,    5,   62,\n",
       "        881,  882,   14, 6052,  883,  124,  675,  235,  523,   12,  884,\n",
       "        885,   39,  886,    1,  649,  886,   39,   62,  194,  887,  888,\n",
       "       6052, 6052,  889,  890, 6052,  891,  883,  124,  892,    5,  893,\n",
       "        142,    1,  249,  250,  894,   32,  895,  896,    1,   32,  857,\n",
       "        533,  772,    5,  327,   42,  897,  898,  899,    5,  900,  834,\n",
       "        901,   39,  902,  834,  903,   42, 1236,  229,  900,  834,  126,\n",
       "       2275,  391,  753,    1,  249,  250,  194, 6052,  717,  111,  963,\n",
       "        886, 6052,  142,    1, 1222, 4085,    1,   32, 2167, 6052,  526,\n",
       "         99,  754,   32,  575,  328,  177,  883, 6052, 1193, 5198,  397,\n",
       "         21,  325,   21,   37, 1256,  131,  510, 5199,   39,   99,  874,\n",
       "       4132,   80,  989,  881,   42,  833,  874,  246,  727,    5,   32,\n",
       "       1102,   62,  567,   42,  883, 2604,   62, 1526,   39, 1098,   25,\n",
       "       4488,   62,   76,   80,  235, 1932,  319,   42, 2211,   37, 1291,\n",
       "          1,  235,  319,  246,  309,  428, 1730,   32,    9,  428, 1079,\n",
       "          5,  586,  367,   42, 3190,  898, 1163,  370, 1731,  523,   12,\n",
       "        524,   32,  893,  142,   42, 3129,  262,  235,  325, 1922, 6052,\n",
       "          1,  871,   46,  235,   74,    1,  524,    1,   32,  567,    5,\n",
       "       1032,  772,  510,    7,  244, 6052,   18,  841,   42, 2532,   62,\n",
       "       6052,    5, 1028,  301,  432,  238,  724,  244,    5,  228,  229,\n",
       "       5114,   32,  834,  158, 2334,  805,  312,  515,  235,  325,   42,\n",
       "       3365,   62,  155,  628,  902,  871,   32,  235,  325,  388,    5,\n",
       "        158, 2334, 1658,  312,  203,  240,  235,  523,   39,  142, 1439,\n",
       "        428,   42, 4898,   10, 5197,    1,  902,  834,    9,  464,   42,\n",
       "        600,   35,   23,  914,    5, 1029,  871,   32,   23, 1490,    5,\n",
       "        138,  244,    1,  249,  250,  194, 2515, 2880,    1, 1169,    1,\n",
       "         32, 4588,  246,  136, 3596,  111, 5266,   42,  908,    5,  235,\n",
       "        236,  281, 1082,    1,  249,  250,  830, 2631,   32, 1434, 1082,\n",
       "         42,  243,  244, 3133,  871, 5232, 3471,    1,  244,   21,   37,\n",
       "        660,  921,  131,   39, 2560,   42, 4365, 3471,   35, 3584,  165,\n",
       "       5228,    1,  391, 5267,    1, 4430, 4021,    1,   32, 1032, 5268,\n",
       "         42, 3248,  830, 3090,  728,   62,  155,   39,  325,    9,   18,\n",
       "       5269,   42,  140,  830,  238,  126,  461,   14,   62, 1954,   39,\n",
       "        235, 1932,  319,   32,   21,   62, 6052, 1386,  219,  235, 1195,\n",
       "        391,  250,  229, 5114,   32,  834,   42, 4123, 2451, 6052, 1502,\n",
       "        165,  194, 6052, 6052, 6052,    1, 1514,    1, 5270,    1, 1195,\n",
       "        325, 3358, 4242,   80,  610,  886,    1, 5195, 5196, 1504, 5088,\n",
       "          1, 1507,    1, 1509,   42, 1510, 1511,  165, 1512, 1513,    1,\n",
       "       1514,    1, 1515,    1, 5271, 5272,    1, 5273,    1,   32,   62,\n",
       "       1520,   42, 1519, 1521,   42, 6054], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for converting tensors to words\n",
    "to_str_pred = lambda w, l: str(\" \".join([info['ind2word'][x] for x in list( filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy()))][:l.data.cpu()[0]]))[8:]\n",
    "to_str_gt = lambda w: str(\" \".join([info['ind2word'][x] for x in filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy())]))[8:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_map(tensor):\n",
    "    return Variable(tensor.unsqueeze(0), volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_16912\\881476409.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(tensor.unsqueeze(0), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "doc_tensor = var_map(torch.from_numpy(doc))\n",
    "doc_lens = var_map(torch.LongTensor([len(doc)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Summary:  ( Diagnosis ) : Heart symptoms may several factors may involved , : - Biological differences . People bipolar ( UNK ) . A blood small placenta baby born . A also found UNK UNK UNK . UNK\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m qBot\u001b[39m.\u001b[39mobserve(\u001b[39mround\u001b[39m, ques\u001b[39m=\u001b[39mdoc_tensor, quesLens\u001b[39m=\u001b[39mdoc_lens)\n\u001b[0;32m     20\u001b[0m \u001b[39m# aBot.observe(round, ques=doc_tensor, quesLens=doc_lens)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m answers, ansLens \u001b[39m=\u001b[39m aBot\u001b[39m.\u001b[39;49mforwardDecode(\n\u001b[0;32m     24\u001b[0m     beamSize\u001b[39m=\u001b[39;49mbeamSize, inference\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgreedy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     25\u001b[0m aBot\u001b[39m.\u001b[39mobserve(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, ans\u001b[39m=\u001b[39manswers, ansLens\u001b[39m=\u001b[39mansLens)\n\u001b[0;32m     26\u001b[0m qBot\u001b[39m.\u001b[39mobserve(\u001b[39mround\u001b[39m, ans\u001b[39m=\u001b[39manswers, ansLens\u001b[39m=\u001b[39mansLens)\n",
      "File \u001b[1;32mc:\\Users\\anest\\Desktop\\uni\\thesis\\lc_mas_torch\\lc\\models\\lc_answerer.py:96\u001b[0m, in \u001b[0;36mAnswerer.forwardDecode\u001b[1;34m(self, inference, beamSize, maxSeqLen)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforwardDecode\u001b[39m(\u001b[39mself\u001b[39m, inference\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msample\u001b[39m\u001b[39m'\u001b[39m, beamSize\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, maxSeqLen\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m):\n\u001b[0;32m     83\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39m    Decode a sequence (answer) using either sampling or greedy inference.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m    An answer is decoded given the current state (dialog history). This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39m        maxSeqLen : Maximum length of token sequence to generate\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     encStates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder()\n\u001b[0;32m     97\u001b[0m     answers, ansLens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mforwardDecode(\n\u001b[0;32m     98\u001b[0m         encStates,\n\u001b[0;32m     99\u001b[0m         maxSeqLen\u001b[39m=\u001b[39mmaxSeqLen,\n\u001b[0;32m    100\u001b[0m         inference\u001b[39m=\u001b[39minference,\n\u001b[0;32m    101\u001b[0m         beamSize\u001b[39m=\u001b[39mbeamSize)\n\u001b[0;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m answers, ansLens\n",
      "File \u001b[1;32mc:\\Users\\anest\\anaconda3\\envs\\lgenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\anest\\Desktop\\uni\\thesis\\lc_mas_torch\\lc\\models\\encoders\\lc_hre.py:255\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedDialog(dialogIdx)\n\u001b[0;32m    254\u001b[0m \u001b[39m# Latest dialogRNN hidden state\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m dialogHidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialogHiddens[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39m]\n\u001b[0;32m    257\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mReturn hidden (H_link) and cell (C_link) states as per the following rule:\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39m(Currently this is defined only for numLayers == 2)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39m        Layer 1 : DialogRNN hidden state (dialogRNN)\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misAnswerer:\n\u001b[0;32m    273\u001b[0m     \u001b[39m# Latest quesRNN states\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if aBot:\n",
    "    aBot.eval(), aBot.reset()\n",
    "    aBot.observe(\n",
    "        -1, document=doc_tensor, documentLens=doc_lens)\n",
    "    \n",
    "if qBot:\n",
    "    qBot.train(), qBot.reset()\n",
    "    qBot.observe(-1, document=doc_tensor, documentLens=doc_lens)\n",
    "\n",
    "numRounds = 10\n",
    "beamSize = 5\n",
    "summ, summLens = qBot.predictSummary(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "print('----------------------------------------')\n",
    "print(\"Summary: \", to_str_gt(summ[0]))    \n",
    "for round in range(numRounds):\n",
    "    questions, quesLens = qBot.forwardDecode(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "    qBot.observe(round, ques=doc_tensor, quesLens=doc_lens)\n",
    "    aBot.observe(round, ques=doc_tensor, quesLens=doc_lens)\n",
    "    \n",
    "    \n",
    "    answers, ansLens = aBot.forwardDecode(\n",
    "        beamSize=beamSize, inference='greedy')\n",
    "    aBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    qBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    \n",
    "    # Printing\n",
    "    print(\"Q%d: \"%(round+1), to_str_gt(questions[0]))\n",
    "    print(\"A%d: \"%(round+1), to_str_gt(answers[0]))\n",
    "    summ, summLens = qBot.predictSummary(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "    print('----------------------------------------')\n",
    "    print(\"Summary: \", to_str_gt(summ[0]))\n",
    "\n",
    "\n",
    "summ, summLens = qBot.predictSummary(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "print('----------------------------------------')\n",
    "print(\"Summary: \", to_str_gt(summ[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( Diagnosis ) : Heart may increase disorder : - several pregnancy cause heart heart type body . UNK ) . UNK cause health . This fungus found UNK UNK UNK UNK - UNK blood pressure UNK . Thi'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_str_gt(summ[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Rouge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Rouge()\u001b[39m.\u001b[39mget_scores(summary, to_str_gt(summ[\u001b[39m0\u001b[39m]), avg\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Rouge' is not defined"
     ]
    }
   ],
   "source": [
    "Rouge().get_scores(summary, to_str_gt(summ[0]), avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.024734982332155476,\n",
       "  'p': 0.30434782608695654,\n",
       "  'f': 0.045751632596650896},\n",
       " 'rouge-2': {'r': 0.002188183807439825,\n",
       "  'p': 0.03125,\n",
       "  'f': 0.004089978326956174},\n",
       " 'rouge-l': {'r': 0.024734982332155476,\n",
       "  'p': 0.30434782608695654,\n",
       "  'f': 0.045751632596650896}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rouge().get_scores(to_str_gt(summ[0]), docs, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "heart\n",
      "-\n",
      "blood\n",
      "pressure\n",
      "-\n",
      "cause\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for word in summary.split(' '):\n",
    "    if word in to_str_gt(summ[0]).split(' '):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a2976d16502cff2e17b6fe6532cd24781aa51a139832d843a9c81ff15d5592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
