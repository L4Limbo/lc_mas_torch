{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import lc_options\n",
    "from utils import lc_utilities as utils\n",
    "from rouge import Rouge\n",
    "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy import spatial\n",
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    'data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json file: data/processed_data/processed_data.json\n",
      "Vocab size with <START>, <END>: 4952\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "\n",
    "params = {\n",
    "    # processed data\n",
    "    'inputJson': \"data/processed_data/processed_data.json\",\n",
    "    # No need for GPU\n",
    "    'useGPU': False, \n",
    "    # Abot checkpoint\n",
    "    'startFrom': \"./checkpoints/rl_rouge/abot_ep_19.vd\",\n",
    "    # Qbot checkpoint\n",
    "    'qstartFrom': \"./checkpoints/rl_rouge/qbot_ep_19.vd\",\n",
    "    'beamSize': 5,\n",
    "}\n",
    "\n",
    "# RNG seed\n",
    "manualSeed = 1597\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if params['useGPU']:\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "print('Loading json file: ' + params['inputJson'])\n",
    "with open(params['inputJson'], 'r') as fileId:\n",
    "    info = json.load(fileId)\n",
    "\n",
    "wordCount = len(info['word2ind'])\n",
    "# Add <START> and <END> to vocabulary\n",
    "info['word2ind']['<START>'] = wordCount + 1\n",
    "info['word2ind']['<END>'] = wordCount + 2\n",
    "startToken = info['word2ind']['<START>']\n",
    "endToken = info['word2ind']['<END>']\n",
    "# Padding token is at index 0\n",
    "vocabSize = wordCount + 3\n",
    "print('Vocab size with <START>, <END>: %d' % vocabSize)\n",
    "\n",
    "# Construct the reverse map\n",
    "info['ind2word'] = {\n",
    "    int(ind): word\n",
    "    for word, ind in info['word2ind'].items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "def loadModel(params, agent='abot'):\n",
    "    # should be everything used in encoderParam, decoderParam below\n",
    "    encoderOptions = [\n",
    "        'encoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'useHistory', 'numRounds', 'dropout', 'useSumm'\n",
    "    ]\n",
    "    decoderOptions = [\n",
    "        'decoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'dropout'\n",
    "    ]\n",
    "    modelOptions = encoderOptions + decoderOptions\n",
    "\n",
    "    mdict = None\n",
    "    gpuFlag = params['useGPU']\n",
    "    startArg = 'startFrom' if agent == 'abot' else 'qstartFrom'\n",
    "    assert params[startArg], \"Need checkpoint for {}\".format(agent)\n",
    "\n",
    "    if params[startArg]:\n",
    "        print('Loading model (weights and config) from {}'.format(\n",
    "            params[startArg]))\n",
    "\n",
    "        if gpuFlag:\n",
    "            mdict = torch.load(params[startArg])\n",
    "        else:\n",
    "            mdict = torch.load(params[startArg],\n",
    "                map_location=lambda storage, location: storage)\n",
    "\n",
    "        # Model options is a union of standard model options defined\n",
    "        # above and parameters loaded from checkpoint\n",
    "        modelOptions = list(set(modelOptions).union(set(mdict['params'])))\n",
    "        for opt in modelOptions:\n",
    "            if opt not in params:\n",
    "                params[opt] = mdict['params'][opt]\n",
    "\n",
    "            elif params[opt] != mdict['params'][opt]:\n",
    "                # Parameters are not overwritten from checkpoint\n",
    "                pass\n",
    "\n",
    "    # Initialize model class\n",
    "    encoderParam = {k: params[k] for k in encoderOptions}\n",
    "    decoderParam = {k: params[k] for k in decoderOptions}\n",
    "\n",
    "    encoderParam['startToken'] = encoderParam['vocabSize'] - 2\n",
    "    encoderParam['endToken'] = encoderParam['vocabSize'] - 1\n",
    "    decoderParam['startToken'] = decoderParam['vocabSize'] - 2\n",
    "    decoderParam['endToken'] = decoderParam['vocabSize'] - 1\n",
    "\n",
    "    if agent == 'abot':\n",
    "        encoderParam['type'] = params['encoder']\n",
    "        decoderParam['type'] = params['decoder']\n",
    "        encoderParam['isAnswerer'] = True\n",
    "        from lc.models.lc_answerer import Answerer\n",
    "        model = Answerer(encoderParam, decoderParam)\n",
    "\n",
    "    elif agent == 'qbot':\n",
    "        encoderParam['type'] = params['qencoder']\n",
    "        decoderParam['type'] = params['qdecoder']\n",
    "        encoderParam['isAnswerer'] = False\n",
    "        encoderParam['useSumm'] = False\n",
    "        from lc.models.lc_questioner import Questioner\n",
    "        model = Questioner(\n",
    "            encoderParam,\n",
    "            decoderParam,\n",
    "            summSize=200)\n",
    "\n",
    "    if params['useGPU']:\n",
    "        model.cuda()\n",
    "\n",
    "    if mdict:\n",
    "        model.load_state_dict(mdict['model'])\n",
    "        \n",
    "    print(\"Loaded agent {}\".format(agent))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Helpers\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "ind_map = lambda words: np.array([info['word2ind'].get(word, info['word2ind']['UNK']) \n",
    "                                  for word in words], dtype='int64')\n",
    "\n",
    "tokenize = lambda string: ['<START>'] + word_tokenize(string) + ['<END>']\n",
    "\n",
    "to_str_gt = lambda w: str(\" \".join([info['ind2word'][x] for x in filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy())]))[8:-6]\n",
    "\n",
    "to_str_pred = lambda w, l: str(\" \".join([info['ind2word'][x] for x in list( filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy()))][:l.data.cpu()[0]]))[8:]\n",
    "\n",
    "def var_map(tensor):\n",
    "    return Variable(tensor.unsqueeze(0), volatile=True)\n",
    "\n",
    "def string_conv(string):\n",
    "\n",
    "    words = nltk.word_tokenize(string)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "    string = word_tokenize(' '.join(words))\n",
    "    \n",
    "    clear_seq = []\n",
    "    for word in string:\n",
    "        if (word not in stop_words):\n",
    "            clear_seq.append(word)\n",
    "            \n",
    "    string = ' '.join(clear_seq)\n",
    "    string_tokens = tokenize(string)\n",
    "    string = ind_map(string_tokens)\n",
    "    string_tensor = var_map(torch.from_numpy(string))\n",
    "    string_lens = var_map(torch.LongTensor([len(string)]))\n",
    "    \n",
    "    return string_tensor, string_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec similarity\n",
    "\n",
    "def word2vec_transform(sequence):\n",
    "    vectorized = []\n",
    "    words = word_tokenize(sequence)\n",
    "    seq_tokens = [word.lower() for word in words if word.isalnum()]\n",
    "    \n",
    "    for word in seq_tokens:\n",
    "        try:\n",
    "            vectorized.append(word2vec[word])\n",
    "        except:\n",
    "            vectorized.append(np.zeros(300,))\n",
    "            \n",
    "    return np.array(vectorized)\n",
    "\n",
    "def similarity_cosine(vec1, vec2):\n",
    "    cosine_distance = spatial.distance.cosine(vec1, vec2)\n",
    "    return 1-cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "doc_data = json.load(open('data/generated_data/gen_dataset.json'))['data']['dialogs']\n",
    "summ_data = json.load(open('data/generated_data/summary_dataset.json'))\n",
    "\n",
    "eval_data = []\n",
    "\n",
    "for doc in doc_data:\n",
    "    eval_data.append({\n",
    "        'doc': doc['document'],\n",
    "        'summ': summ_data[doc['summary']]\n",
    "    })\n",
    "\n",
    "# 0-117 -> train data\n",
    "# 117-156 -> eval data\n",
    "eval_data = eval_data[117:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Congenital heart disease Summary Congenital heart disease (CHD) is a problem with the heart's structure and function that is present at birth. Causes CHD can describe a number of different problems affecting the heart. It is the most common type of birth defect. CHD causes more deaths in the first year of life than any other birth defects. CHD is often divided into two types: cyanotic (blue skin color caused by a lack of oxygen) and non-cyanotic. The following lists cover the most common CHDs: Cyanotic: Ebstein's anomaly Hypoplastic left heart Pulmonary atresia Tetralogy of Fallot Total anomalous pulmonary venous return Transposition of the great vessels Tricuspid atresia Truncus arteriosus Non-cyanotic: Aortic stenosis Bicuspid aortic valve Atrial septal defect (ASD) Atrioventricular canal (endocardial cushion defect) Coarctation of the aorta Patent ductus arteriosus (PDA) Pulmonic stenosis Ventricular septal defect (VSD) These problems may occur alone or together. Most children with CHD do not have other types of birth defects. However, heart defects may be part of genetic and chromosomal syndromes. Some of these syndromes may be passed down through families. Examples include: DiGeorge syndrome Down syndrome Marfan syndrome Noonan syndrome Edwards syndrome Trisomy 13 Turner syndrome Often, no cause for the heart disease can be found. CHDs continue to be investigated and researched. Drugs such as retinoic acid for acne, chemicals, alcohol, and infections (such as rubella) during pregnancy can contribute to some congenital heart problems. Poorly controlled blood sugar in women who have diabetes during pregnancy has also been linked to a high rate of congenital heart defects. Symptoms Symptoms depend on the condition. Although CHD is present at birth, the symptoms may not appear right away. Defects such as coarctation of the aorta may not cause problems for years. Other problems, such as a small VSD, ASD, or PDA may never cause any problems. Exams and Tests Most congenital heart defects are found during a pregnancy ultrasound. When a defect is found, a pediatric heart doctor, surgeon, and other specialists can be there when the baby is delivered. Having medical care ready at the delivery can mean the difference between life and death for some babies. Which tests are done on the baby depend on the defect and the symptoms. Treatment Which treatment is used, and how well the baby responds to it, depends on the condition. Many defects need to be followed carefully. Some will heal over time, while others will need to be treated. Some CHDs can be treated with medicine alone. Others need to be treated with one or more heart procedures or surgeries. Prevention Women who are pregnant should get good prenatal care: Avoid alcohol and illegal drugs during pregnancy. Tell your health care provider that you are pregnant before taking any new medicines. Have a blood test early in your pregnancy to see if you are immune to rubella. If you are not immune, avoid any possible exposure to rubella and get vaccinated right after delivery. Pregnant women who have diabetes should try to get good control over their blood sugar level. Certain genes may play a role in CHD. Many family members may be affected. Talk to your provider about genetic counseling and screening if you have a family history of CHD. Review Date 12/8/2017 Updated by: Steven Kang, MD, Director, Cardiac Electrophysiology, Alta Bates Summit Medical Center, Stanford Healthcare, Oakland, CA. Review provided by VeriMed Healthcare Network. Also reviewed by David Zieve, MD, MHA, Medical Director, Brenda Conaway, Editorial Director, and the A.D.A.M. Editorial team. \n",
      "--------------------------------------------------\n",
      "Most cases of CCHD are sporadic, which means they occur in people with no history of the disorder in their family. However, close relatives (such as siblings) of people with CCHD may have an increased risk of being born with a heart defect compared with people in the general population. A variety of genetic and environmental factors likely contribute to this complex condition. Changes in single genes have been associated with CCHD. Studies suggest that these genes are involved in normal heart development before birth. Most of the identified mutations reduce the amount or function of the protein that is produced from a specific gene, which likely impairs the normal formation of structures in the heart. Potential risk factors that have been studied include exposure to certain chemicals or drugs before birth, viral infections (such as rubella and influenza) that occur during pregnancy, and other maternal illnesses including diabetes and phenylketonuria. Although researchers are examining risk factors that may be associated with this complex condition, many of these factors remain unknown.\n"
     ]
    }
   ],
   "source": [
    "# Number 0-155\n",
    "num = 25\n",
    "# Summary-Goal for Example\n",
    "doc_example = doc_data[num]['document']\n",
    "print(doc_example)\n",
    "\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Summary-Goal for Example\n",
    "summary_example = summ_data[doc_data[num]['summary']]\n",
    "print(summary_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_10632\\2946741690.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(tensor.unsqueeze(0), volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (weights and config) from ./checkpoints/rl_rouge/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rouge/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Q0: how do you get pulmonary hypertension ?\n",
      "A0: the right side of the heart pumps blood through the lungs where it picks up oxygen blood returns to the left side of the heart where it is pumped to the rest of the body when the small arteries blood\n",
      "Q1: what is the cause of bulimia eye ?\n",
      "A1: achondroplasia is a rare genetic disorder characterized by UNK head and facial and skeletal abnormalities delayed intellectual development short stature and hypotonia the disorder is caused by a defective gene UNK which is found in\n",
      "Q2: what is the name of the eye of the eye of the eye of the eye called ?\n",
      "A2: syndrome treatment treatment is a group of medication and the emphasis is on the most common type of dwarfism achondroplasia may be inherited as an autosomal dominant trait which means that if the child gets the defective gene in the\n",
      "Q3: what causes the risk of the eye of the eye of the eye of the eye lipids in the eye lipids in the eye of the eye ?\n",
      "A3: suicide forearms\n",
      "Q4: what type of seizures eye ?\n",
      "A4: most absence pneumonia is a type of eating disorder binge eating disorder is the most common type of dwarfism achondroplasia may be inherited as an autosomal dominant trait which means that if the chromosomal analysis called a karyotype 3 5\n",
      "Q5: what is epilepsy ?\n",
      "A5: epilepsy\n",
      "Q6: what is epilepsy ?\n",
      "A6: epilepsy\n",
      "Q7: what is epilepsy ?\n",
      "A7: epilepsy\n",
      "Q8: what is epilepsy ?\n",
      "A8: epilepsy\n",
      "Q9: what is epilepsy ?\n",
      "A9: epilepsy\n",
      "S-1: cough old many early describe body doctor determining difference weight gain microscope people paroxysmal poor exercising join quarter childbirth people tendinitis will relievers horseshoe well lupus pulmonale treatments appetite skills pediatrician counselor pulmonale spina rubella beams stis shoes unconsciousness neuromuscular scoliosis pulmonale blood controlling burned stis chlamydia syphilis will cause alone coal karyotype diarrhea function erection people old tomography course infant linked paroxysmal certain oral injury foot symptoms cough suddenly appear mayo management glucose understand bifida old tomography\n"
     ]
    }
   ],
   "source": [
    "numRounds = 10\n",
    "beamSize = 5\n",
    "\n",
    "summary_tensor, summary_lens = string_conv(summary_example)\n",
    "document_tensor, document_lens = string_conv(doc_example)\n",
    "\n",
    "aBot = None\n",
    "qBot = None\n",
    "\n",
    "# load aBot\n",
    "if params['startFrom']:\n",
    "    aBot = loadModel(params, 'abot')\n",
    "    assert aBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    aBot.eval()\n",
    "    \n",
    "# load qBot\n",
    "if params['qstartFrom']:\n",
    "    qBot = loadModel(params, 'qbot')\n",
    "    assert qBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    qBot.eval()\n",
    "\n",
    "\n",
    "# prepare for dialogue\n",
    "if aBot:\n",
    "    aBot.eval(), aBot.reset()\n",
    "    aBot.train(), aBot.reset()\n",
    "    aBot.observe(-1, summary=summary_tensor, summaryLens=summary_lens, document=document_tensor,\n",
    "                    documentLens=document_lens)\n",
    "\n",
    "if qBot:\n",
    "    qBot.eval(), qBot.reset()\n",
    "    qBot.observe(-1, document=document_tensor,\n",
    "                    documentLens=document_lens)\n",
    "summ, summ_lens = qBot.predictSummary(inference='greedy')\n",
    "\n",
    "# dialogue before summ generation\n",
    "for round in range(numRounds):\n",
    "    questions, quesLens = qBot.forwardDecode(\n",
    "        beamSize=beamSize, inference='greedy')\n",
    "    qBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "    aBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "    answers, ansLens = aBot.forwardDecode(\n",
    "        beamSize=beamSize, inference='greedy')\n",
    "    aBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    qBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    \n",
    "    summ, summ_lens = qBot.predictSummary(inference='greedy')\n",
    "    print('Q%s:' %round, to_str_pred(questions[0], quesLens))\n",
    "    print('A%s:' %round, to_str_pred(answers[0], ansLens))\n",
    "\n",
    "print('S%s:' %-1, to_str_pred(summ[0], summ_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a2976d16502cff2e17b6fe6532cd24781aa51a139832d843a9c81ff15d5592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
