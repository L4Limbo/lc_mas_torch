{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import lc_options\n",
    "from utils import lc_utilities as utils\n",
    "from rouge import Rouge\n",
    "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy import spatial\n",
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    'data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json file: data/processed_data/processed_data.json\n",
      "Vocab size with <START>, <END>: 4867\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'inputJson': \"data/processed_data/processed_data.json\",\n",
    "    'useGPU': False,\n",
    "    # A-Bot checkpoint\n",
    "    'startFrom': \"./checkpoints/sl_1/abot_ep_50.vd\",\n",
    "    'qstartFrom': \"./checkpoints/sl_1/qbot_ep_40.vd\",\n",
    "    'beamSize': 5,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'inputJson': \"data/processed_data/processed_data.json\",\n",
    "    'useGPU': False,\n",
    "    # A-Bot checkpoint\n",
    "    'startFrom': \"./checkpoints/rl_leven/abot_ep_9.vd\",\n",
    "    'qstartFrom': \"./checkpoints/rl_leven/qbot_ep_9.vd\",\n",
    "    'beamSize': 5,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'inputJson': \"data/processed_data/processed_data.json\",\n",
    "    'useGPU': False,\n",
    "    # A-Bot checkpoint\n",
    "    'startFrom': \"./checkpoints/rl_rougel/abot_ep_19.vd\",\n",
    "    'qstartFrom': \"./checkpoints/rl_rougel/qbot_ep_19.vd\",\n",
    "    'beamSize': 5,\n",
    "}\n",
    "\n",
    "# RNG seed\n",
    "manualSeed = 1597\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if params['useGPU']:\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "print('Loading json file: ' + params['inputJson'])\n",
    "with open(params['inputJson'], 'r') as fileId:\n",
    "    info = json.load(fileId)\n",
    "\n",
    "wordCount = len(info['word2ind'])\n",
    "# Add <START> and <END> to vocabulary\n",
    "info['word2ind']['<START>'] = wordCount + 1\n",
    "info['word2ind']['<END>'] = wordCount + 2\n",
    "startToken = info['word2ind']['<START>']\n",
    "endToken = info['word2ind']['<END>']\n",
    "# Padding token is at index 0\n",
    "vocabSize = wordCount + 3\n",
    "print('Vocab size with <START>, <END>: %d' % vocabSize)\n",
    "\n",
    "# Construct the reverse map\n",
    "info['ind2word'] = {\n",
    "    int(ind): word\n",
    "    for word, ind in info['word2ind'].items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(params, agent='abot'):\n",
    "    # should be everything used in encoderParam, decoderParam below\n",
    "    encoderOptions = [\n",
    "        'encoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'useHistory', 'numRounds', 'dropout', 'useSumm'\n",
    "    ]\n",
    "    decoderOptions = [\n",
    "        'decoder', 'vocabSize', 'embedSize', 'rnnHiddenSize', 'numLayers',\n",
    "        'dropout'\n",
    "    ]\n",
    "    modelOptions = encoderOptions + decoderOptions\n",
    "\n",
    "    mdict = None\n",
    "    gpuFlag = params['useGPU']\n",
    "    startArg = 'startFrom' if agent == 'abot' else 'qstartFrom'\n",
    "    assert params[startArg], \"Need checkpoint for {}\".format(agent)\n",
    "\n",
    "    if params[startArg]:\n",
    "        print('Loading model (weights and config) from {}'.format(\n",
    "            params[startArg]))\n",
    "\n",
    "        if gpuFlag:\n",
    "            mdict = torch.load(params[startArg])\n",
    "        else:\n",
    "            mdict = torch.load(params[startArg],\n",
    "                map_location=lambda storage, location: storage)\n",
    "\n",
    "        # Model options is a union of standard model options defined\n",
    "        # above and parameters loaded from checkpoint\n",
    "        modelOptions = list(set(modelOptions).union(set(mdict['params'])))\n",
    "        for opt in modelOptions:\n",
    "            if opt not in params:\n",
    "                params[opt] = mdict['params'][opt]\n",
    "\n",
    "            elif params[opt] != mdict['params'][opt]:\n",
    "                # Parameters are not overwritten from checkpoint\n",
    "                pass\n",
    "\n",
    "    # Initialize model class\n",
    "    encoderParam = {k: params[k] for k in encoderOptions}\n",
    "    decoderParam = {k: params[k] for k in decoderOptions}\n",
    "\n",
    "    encoderParam['startToken'] = encoderParam['vocabSize'] - 2\n",
    "    encoderParam['endToken'] = encoderParam['vocabSize'] - 1\n",
    "    decoderParam['startToken'] = decoderParam['vocabSize'] - 2\n",
    "    decoderParam['endToken'] = decoderParam['vocabSize'] - 1\n",
    "\n",
    "    if agent == 'abot':\n",
    "        encoderParam['type'] = params['encoder']\n",
    "        decoderParam['type'] = params['decoder']\n",
    "        encoderParam['isAnswerer'] = True\n",
    "        from lc.models.lc_answerer import Answerer\n",
    "        model = Answerer(encoderParam, decoderParam)\n",
    "\n",
    "    elif agent == 'qbot':\n",
    "        encoderParam['type'] = params['qencoder']\n",
    "        decoderParam['type'] = params['qdecoder']\n",
    "        encoderParam['isAnswerer'] = False\n",
    "        encoderParam['useSumm'] = False\n",
    "        from lc.models.lc_questioner import Questioner\n",
    "        model = Questioner(\n",
    "            encoderParam,\n",
    "            decoderParam,\n",
    "            summGenSize=60)\n",
    "\n",
    "    if params['useGPU']:\n",
    "        model.cuda()\n",
    "\n",
    "    if mdict:\n",
    "        model.load_state_dict(mdict['model'])\n",
    "        \n",
    "    print(\"Loaded agent {}\".format(agent))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_map = lambda words: np.array([info['word2ind'].get(word, info['word2ind']['UNK']) \n",
    "                                  for word in words], dtype='int64')\n",
    "\n",
    "tokenize = lambda string: ['<START>'] + word_tokenize(string) + ['<END>']\n",
    "\n",
    "to_str_gt = lambda w: str(\" \".join([info['ind2word'][x] for x in filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy())]))[8:-6]\n",
    "\n",
    "to_str_pred = lambda w, l: str(\" \".join([info['ind2word'][x] for x in list( filter(\n",
    "        lambda x:x>0,w.data.cpu().numpy()))][:l.data.cpu()[0]]))[8:]\n",
    "\n",
    "def var_map(tensor):\n",
    "    return Variable(tensor.unsqueeze(0), volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_conv (string):\n",
    "    words = nltk.word_tokenize(string)\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    string = ' '.join(words)\n",
    "\n",
    "    string_tokens = tokenize(string)\n",
    "    string = ind_map(string_tokens)\n",
    "\n",
    "    string_tensor = var_map(torch.from_numpy(string))\n",
    "    string_lens = var_map(torch.LongTensor([len(string)]))\n",
    "    \n",
    "    return string_tensor, string_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_data = json.load(open('data/generated_data/gen_dataset.json'))['data']['dialogs']\n",
    "summ_data = json.load(open('data/generated_data/summary_dataset.json'))\n",
    "\n",
    "eval_data = []\n",
    "\n",
    "for doc in doc_data:\n",
    "    eval_data.append({\n",
    "        'doc': doc['document'],\n",
    "        'summ': summ_data[doc['summary']]\n",
    "    })\n",
    "    \n",
    "eval_data = eval_data[::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_10756\\4003069411.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(tensor.unsqueeze(0), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "summary = \"asthma \" * 100\n",
    "document = \"Burns Overview Burns can be minor medical problems or life-threatening emergencies. Many people die each year from fire-related burn injuries. Electricity and chemicals also cause severe burns. Scalding liquids are the most common cause of burns in children. Treatment of burns depends on the location and severity of the injury. Sunburns and small scalds can usually be treated at home. Deep or widespread burns need immediate medical attention. People with severe burns often require treatment at specialized burn centers. They may need skin grafts to cover large wounds or to minimize scarring with deep wounds. And they may need emotional support and months of follow-up care, such as physical therapy. Symptoms Burns don't affect the skin uniformly, so a single injury can reach varying depths. Distinguishing a minor burn from a more serious burn involves determining the extent of tissue damage. The following are three classifications of burns: - First-degree burn. This minor burn affects only the outer layer of the skin (epidermis). It may cause redness, swelling and pain. It usually heals with first-aid measures within several days to a week. Sunburn is a classic example. - Second-degree burn. This type of burn affects both the epidermis and the second layer of skin (dermis). It may cause red, white or splotchy skin, pain, and swelling. And the wound often looks wet or moist. Blisters may develop, and pain can be severe. Deep second-degree burns can cause scarring. - Third-degree burn. This burn reaches into the fat layer beneath the skin. Burned areas may be charred black or white. The skin may look waxy or leathery. Third-degree burns can destroy nerves, causing numbness. A person with this type of burn may also have difficulty breathing or experience smoke inhalation or carbon monoxide poisoning. When to see a doctor Seek emergency medical assistance for: - Burns that cover the hands, feet, face, groin, buttocks, a major joint or a large area of the body - Deep burns, which means burns affecting all layers of the skin and even other tissues - Burns caused by chemicals or electricity - Difficulty breathing or burns to the airway Minor burns can be cared for at home, but call your doctor if you experience: - Large blisters - Signs of infection, such as oozing from the wound, increased pain, redness and swelling - A burn or blister that doesn't heal in several weeks - New, unexplained symptoms - Significant scarring Causes Many things can cause burns, including: - Fire - Hot liquid or steam - Hot metal, glass or other objects - Electrical currents - Radiation from X-rays or radiation therapy to treat cancer - Sunlight or ultraviolet light from a sunlamp or tanning bed - Chemicals such as strong acids, lye, paint thinner or gasoline - Abuse Complications Deep or widespread burns can lead to many complications, including: - Infection. Burns can leave skin vulnerable to bacterial infection and increase your risk of sepsis. Sepsis is a life-threatening infection that travels through the bloodstream and affects your whole body. It progresses rapidly and can cause shock and organ failure. - Low blood volume. Burns can damage blood vessels and cause fluid loss. This may result in low blood volume (hypovolemia). Severe blood and fluid loss prevents the heart from pumping enough blood to the body. - Dangerously low body temperature. The skin helps control the body's temperature, so when a large portion of the skin is injured, you lose body heat. This increases your risk of a dangerously low body temperature (hypothermia). Hypothermia is a condition in which the body loses heat faster than it can produce heat. - Breathing problems. Breathing hot air or smoke can burn airways and cause breathing (respiratory) difficulties. Smoke inhalation damages the lungs and can cause respiratory failure. - Scarring. Burns can cause scars and ridged areas caused by an overgrowth of scar tissue (keloids). - Bone and joint problems. Deep burns can limit movement of the bones and joints. Scar tissue can form and cause shortening and tightening of skin, muscles or tendons (contractures). This condition may permanently pull joints out of position. Diagnosis During the physical exam, your doctor will examine your burned skin and determine what percentage of your total body surface area is involved. In general, an area of skin roughly equal to the size of your palm equals 1 percent of your total body surface area. For people ages 10 to 40, the American Burn Association defines a severe burn as one that involves 25 percent total body surface area or any burn involving the eyes, ears, face, hands, feet or groin. You'll also be examined for other injuries and to determine whether the burn has affected the rest of your body. You may need lab tests, X-rays or other diagnostic procedures. Treatment Treatment of burns depends on the type and extent of the injuries. Most minor burns can be treated at home using over-the-counter products or aloe. They usually heal within a few weeks. For serious burns, after appropriate first aid care and wound assessment, your treatment may involve medications, wound dressings, therapy and surgery. The goals of treatment are to control pain, remove dead tissue, prevent infection, reduce scarring, regain function and address emotional needs. You may need months of additional treatments and therapy. This may be done during a hospital stay, on an outpatient basis or at home. Factors affecting this choice include your wishes, other conditions and abilities, such as whether you're able to change bandages. Medications and wound healing products For major burns, various medications and products are used to encourage healing. - Water-based treatments. Your care team may use techniques such as ultrasound mist therapy to clean and stimulate the wound tissue. - Fluids to prevent dehydration. You may need intravenous (IV) fluids to prevent dehydration and organ failure. - Pain and anxiety medications. Healing burns can be incredibly painful. You may need morphine and anti-anxiety medications - particularly for dressing changes. - Burn creams and ointments. Your care team can select from a variety of topical products for wound healing. These help keep the wound moist, reduce pain, prevent infection and speed healing. - Dressings. Your care team may also use various specialty wound dressings. These create a moist environment that fights infection and helps the burn heal. - Drugs that fight infection. If you develop an infection, you may need IV antibiotics. - Tetanus shot. Your doctor might recommend a tetanus shot after a burn injury. Physical and occupational therapy If the burned area is large, especially if it covers any joints, you may need physical therapy exercises. These can help stretch the skin so the joints can remain flexible. Other types of exercises can improve muscle strength and coordination. And occupational therapy may help if you have difficulty doing your normal daily activities. Surgical and other procedures You may need one or more of the following procedures: - Breathing assistance. If you've been burned on the face or neck, your throat may swell shut. If that appears likely, your doctor may insert a tube down your windpipe (trachea) to keep oxygen supplied to your lungs. - Tube feeding. Your metabolism goes into overdrive when your body starts trying to heal your burns. To provide adequate nutrition for this task, you doctor may thread a feeding tube through your nose to your stomach. - Easing blood flow around the wound. If a burn scab (eschar) goes completely around a limb, it can tighten and cut off the blood circulation. A scab (eschar) that goes completely around the chest can make it difficult to breathe. Your doctor may cut the eschar in several places to relieve this pressure. This procedure is called decompression. - Skin grafts. A skin graft is a surgical procedure in which sections of your own healthy skin are used to replace the scar tissue caused by deep burns. Donor skin from cadavers or pigs can be used as a temporary solution. - Plastic surgery. Plastic surgery (reconstruction) can improve the appearance of burn scars and increase the flexibility of joints affected by scarring. Lifestyle and home remedies To treat minor burns, follow these steps: - Cool the burn. Run cool (not cold) tap water over the burn for 10 to 15 minutes or until the pain eases. Or apply a clean towel dampened with cool tap water. Don't use ice. Putting ice directly on a burn can cause further damage to the tissue. - Remove rings or other tight items from the burned area. Try to do this quickly and gently, before the area swells. - Don't break small blisters (no bigger than your little fingernail). If blisters break, gently clean the area with mild soap and water, apply an antibiotic ointment, and cover it with a nonstick gauze bandage. - Apply moisturizer or aloe vera lotion or gel. This may soothe the area and prevent dryness as the wound heals. - If needed, take an over-the-counter pain reliever. Nonprescription products include ibuprofen (Advil, Motrin IB, others), naproxen (Aleve) and acetaminophen (Tylenol, others). - Consider a tetanus shot. Make sure that your tetanus booster is up to date. Doctors recommend people get a tetanus shot at least every 10 years. Whether your burn was minor or serious, use sunscreen and moisturizer regularly once the wound is healed.\"\n",
    "\n",
    "summary_tensor, summary_lens = string_conv(summary)\n",
    "document_tensor, document_lens = string_conv(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_10756\\4003069411.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(tensor.unsqueeze(0), volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n"
     ]
    }
   ],
   "source": [
    "numRounds = 10\n",
    "beamSize = 5\n",
    "\n",
    "summs_eval = []\n",
    "last_round_ans = []\n",
    "last_round_ques = []\n",
    "\n",
    "for eval in eval_data:\n",
    "    # load data\n",
    "    summary_tensor, summary_lens = string_conv(eval['summ'])\n",
    "    document_tensor, document_lens = string_conv(eval['doc'])\n",
    "    \n",
    "    aBot = None\n",
    "    qBot = None\n",
    "    \n",
    "    # load aBot\n",
    "    if params['startFrom']:\n",
    "        aBot = loadModel(params, 'abot')\n",
    "        assert aBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "        aBot.eval()\n",
    "        \n",
    "    # load qBot\n",
    "    if params['qstartFrom']:\n",
    "        qBot = loadModel(params, 'qbot')\n",
    "        assert qBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "        qBot.eval()\n",
    "\n",
    "\n",
    "    # prepare for dialogue\n",
    "    if aBot:\n",
    "        aBot.eval(), aBot.reset()\n",
    "        aBot.train(), aBot.reset()\n",
    "        aBot.observe(-1, summary=summary_tensor, summaryLens=summary_lens, document=document_tensor,\n",
    "                        documentLens=document_lens)\n",
    "\n",
    "    if qBot:\n",
    "        qBot.eval(), qBot.reset()\n",
    "        qBot.observe(-1, document=document_tensor,\n",
    "                        documentLens=document_lens)\n",
    "    \n",
    "    # dialogue before summ generation\n",
    "    for round in range(numRounds):\n",
    "        questions, quesLens = qBot.forwardDecode(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "        qBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "        aBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "        answers, ansLens = aBot.forwardDecode(\n",
    "            beamSize=beamSize, inference='greedy')\n",
    "        aBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "        qBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "        last_round_ans.append(to_str_pred(answers[0], ansLens))\n",
    "        last_round_ques.append(to_str_pred(questions[0], quesLens))\n",
    "\n",
    "\n",
    "        summ, summ_lens = qBot.predictSummary(inference='greedy')\n",
    "\n",
    "    summs_eval.append({\n",
    "        'gt': eval['summ'],\n",
    "        'gen': to_str_pred(summ[0], summ_lens)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(set(last_round_ans)))\n",
    "print(len(set(last_round_ques)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_transform(sequence):\n",
    "    vectorized = []\n",
    "    words = word_tokenize(sequence)\n",
    "    seq_tokens = [word.lower() for word in words if word.isalpha()]\n",
    "    \n",
    "    for word in seq_tokens:\n",
    "        try:\n",
    "            vectorized.append(word2vec[word])\n",
    "        except:\n",
    "            vectorized.append(np.zeros(300,))\n",
    "            \n",
    "    return np.array(vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_cosine(vec1, vec2):\n",
    "    cosine_distance = spatial.distance.cosine(vec1, vec2)\n",
    "    return 1-cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bipolar',\n",
       " 'blood',\n",
       " 'cancer',\n",
       " 'common',\n",
       " 'condition',\n",
       " 'disorder',\n",
       " 'doctor',\n",
       " 'eventually',\n",
       " 'exercising',\n",
       " 'factors',\n",
       " 'find',\n",
       " 'first',\n",
       " 'genetic',\n",
       " 'growing',\n",
       " 'help',\n",
       " 'include',\n",
       " 'main',\n",
       " 'may',\n",
       " 'pinpoint',\n",
       " 'recommend',\n",
       " 'sibling',\n",
       " 'still',\n",
       " 'trying',\n",
       " 'uncertain'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores = []\n",
    "levenshtein_similarities = []\n",
    "word2vec_similarities = []\n",
    "\n",
    "\n",
    "for pair in summs_eval:\n",
    "    rouge_scores.append(Rouge().get_scores(pair['gt'], pair['gen'], avg=True))\n",
    "    levenshtein_similarities.append(1 -  NormalizedLevenshtein().distance(pair['gt'], pair['gen']))\n",
    "    word2vec_similarities.append(similarity_cosine(word2vec_transform(pair['gt']).mean(axis=0),word2vec_transform(pair['gen']).mean(axis=0)))\n",
    "    \n",
    "common_words = []\n",
    "for pair in summs_eval:\n",
    "    gt_summ = pair['gt'].lower()\n",
    "    gen_summ = pair['gen'].lower()\n",
    "    for word in pair['gen'].split():\n",
    "        if word in pair['gt'].split():\n",
    "            common_words.append(word)\n",
    "\n",
    "set(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_f1 = []\n",
    "rouge_fl = []\n",
    "\n",
    "for score in rouge_scores:\n",
    "    rouge_f1.append(score['rouge-1']['f'])\n",
    "    rouge_fl.append(score['rouge-l']['f'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32484848484848483\n",
      "0.05728376327769347\n",
      "0.20081246378301246\n",
      "------------------------------\n",
      "0.8500129744437055\n",
      "0.260056192119841\n",
      "0.626608367458359\n",
      "------------------------------\n",
      "0.2568807305108998\n",
      "0.0\n",
      "0.041572642321148864\n",
      "------------------------------\n",
      "0.2568807305108998\n",
      "0.0\n",
      "0.041572642321148864\n"
     ]
    }
   ],
   "source": [
    "print(max(levenshtein_similarities))\n",
    "print(min(levenshtein_similarities))\n",
    "print(sum(levenshtein_similarities) / len(levenshtein_similarities))\n",
    "print('------------------------------')\n",
    "print(max(word2vec_similarities))\n",
    "print(min(word2vec_similarities))\n",
    "print(sum(word2vec_similarities) / len(word2vec_similarities))\n",
    "print('------------------------------')\n",
    "print(max(rouge_f1))\n",
    "print(min(rouge_f1))\n",
    "print(sum(rouge_f1) / len(rouge_f1))\n",
    "print('------------------------------')\n",
    "print(max(rouge_fl))\n",
    "print(min(rouge_fl))\n",
    "print(sum(rouge_fl) / len(rouge_fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anest\\AppData\\Local\\Temp\\ipykernel_10756\\4003069411.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(tensor.unsqueeze(0), volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (weights and config) from ./checkpoints/rl_rougel/abot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent abot\n",
      "Loading model (weights and config) from ./checkpoints/rl_rougel/qbot_ep_19.vd\n",
      "Encoder: hre-ques-lateim-hist\n",
      "Decoder: gen\n",
      "Loaded agent qbot\n",
      "Q1:  what are the causes of pulmonary hypertension ?\n",
      "A1:  the right side of the heart pumps blood through the lungs where it picks up oxygen blood returns to the left side of the left side of the left side of the left side of the left side of a\n",
      "Q2:  what is the cause of the symptoms of the UNK of the body ?\n",
      "A2:  the goals of UNK UNK in the blood sugar glucose level of UNK activity to help relax the risk of developing relax the child such as a relative such as a relative such as a relative such as the body\n",
      "Q3:  what is the cause of the heart of UNK ?\n",
      "A3:  most cases of symptoms that starts in the blood sugar glucose level of developing a role in the body when the left side of the left side of the left side of the stress such as a relative such as\n",
      "Q4:  what are the symptoms of the causes of the UNK of the body ?\n",
      "A4:  most cases of symptoms clear on the blood sugar follow a combination of the body when the type of UNK activity to help relax the child such as a relative such as a relative such as a relative such as\n",
      "Q5:  what are the symptoms of the causes of the UNK of the body ?\n",
      "A5:  peripheral neuropathy and symptoms recommends affects the risk of UNK disorder to treat UNK in the type of developing bipolar disorder of the body when the body when a relative such as a relative such as a relative such as\n",
      "Q6:  what are the symptoms of the causes of the UNK of the body ?\n",
      "A6:  peripheral neuropathy of UNK disorder and UNK and UNK and UNK and facial and juice of the body and juice of the body and facial and kidney disease and facial and kidney disease national disabling to ones that is potentially\n",
      "Q7:  what are the cause of the causes of the UNK of the body ?\n",
      "A7:  in general UNK\n",
      "Q8:  what are the risk of the symptoms of UNK ?\n",
      "A8:  most cases of diarrhea clear on the blood sugar follow a couple of developing bipolar disorder of the disease if you may have a relative such as a relative such as a relative such as a relative such as a\n",
      "Q9:  what is the cause of the heart of UNK ?\n",
      "A9:  peripheral neuropathy of UNK disorder and blood pumps blood through the lungs where it picks up oxygen blood returns to the left side of the left side of the left side of the heart where it is pumped to a\n",
      "Q10:  what is the cause of the symptoms of UNK ?\n",
      "A10:  most cases of UNK disorder on the heart pumps blood through the lungs where it picks up oxygen blood returns to the left side of the left side of the left side of the left side of the body when\n",
      "-----------------------------------------------\n",
      "main cancer disorder may include largely disorder may stops movement blood still growing may help UNK exercising UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK\n"
     ]
    }
   ],
   "source": [
    "aBot = None\n",
    "qBot = None\n",
    "\n",
    "summary_tensor, summary_lens = string_conv(eval_data[2]['summ'])\n",
    "document_tensor, document_lens = string_conv(eval_data[3]['doc'])\n",
    "    \n",
    "# load aBot\n",
    "if params['startFrom']:\n",
    "    aBot = loadModel(params, 'abot')\n",
    "    assert aBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    aBot.eval()\n",
    "    \n",
    "# load qBot\n",
    "if params['qstartFrom']:\n",
    "    qBot = loadModel(params, 'qbot')\n",
    "    assert qBot.encoder.vocabSize == vocabSize, \"Vocab size mismatch!\"\n",
    "    qBot.eval()\n",
    "\n",
    "\n",
    "\n",
    "if aBot:\n",
    "    aBot.eval(), aBot.reset()\n",
    "    aBot.train(), aBot.reset()\n",
    "    aBot.observe(-1, summary=summary_tensor, summaryLens=summary_lens, document=document_tensor,\n",
    "                    documentLens=document_lens)\n",
    "\n",
    "if qBot:\n",
    "    qBot.eval(), qBot.reset()\n",
    "    qBot.observe(-1, document=document_tensor,\n",
    "                    documentLens=document_lens)\n",
    "\n",
    "numRounds = 10\n",
    "beamSize = 5\n",
    "summ, summ_lens = qBot.predictSummary(inference='greedy')\n",
    "print('-----------------------------------------------')\n",
    "print(to_str_pred(summ[0], summ_lens))\n",
    "\n",
    "print(Rouge().get_scores(eval_data[2]['summ'], to_str_pred(summ[0], summ_lens), avg=True))\n",
    "print(1 -  NormalizedLevenshtein().distance(eval_data[2]['summ'], to_str_pred(summ[0], summ_lens)))\n",
    "print(similarity_cosine(word2vec_transform(eval_data[2]['summ']).mean(axis=0),word2vec_transform(to_str_pred(summ[0], summ_lens)).mean(axis=0)))\n",
    "print('*************************')\n",
    "for round in range(numRounds):\n",
    "    questions, quesLens = qBot.forwardDecode(\n",
    "        beamSize=beamSize, inference='greedy')\n",
    "    qBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "    aBot.observe(round, ques=questions, quesLens=quesLens)\n",
    "    answers, ansLens = aBot.forwardDecode(\n",
    "        beamSize=beamSize, inference='greedy')\n",
    "    aBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    qBot.observe(round, ans=answers, ansLens=ansLens)\n",
    "    test.append(to_str_pred(questions[0], quesLens))\n",
    "    # print(\"Q%d: \"%(round+1), to_str_pred(questions[0], quesLens))\n",
    "    # print(\"A%d: \"%(round+1), to_str_pred(answers[0], ansLens))\n",
    "\n",
    "summ, summ_lens = qBot.predictSummary(inference='greedy')\n",
    "print('-----------------------------------------------')\n",
    "print(to_str_pred(summ[0], summ_lens))\n",
    "\n",
    "print(Rouge().get_scores(eval_data[2]['summ'], to_str_pred(summ[0], summ_lens), avg=True))\n",
    "print(1 -  NormalizedLevenshtein().distance(eval_data[2]['summ'], to_str_pred(summ[0], summ_lens)))\n",
    "print(similarity_cosine(word2vec_transform(eval_data[2]['summ']).mean(axis=0),word2vec_transform(to_str_pred(summ[0], summ_lens)).mean(axis=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:35:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a2976d16502cff2e17b6fe6532cd24781aa51a139832d843a9c81ff15d5592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
